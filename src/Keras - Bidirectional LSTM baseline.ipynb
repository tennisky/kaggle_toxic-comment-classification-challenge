{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv\n",
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "train = train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154640</th>\n",
       "      <td>b0f437119b56c6f4</td>\n",
       "      <td>\"\\nSo I'm still waiting for an actual reason. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153091</th>\n",
       "      <td>972f3e1770dcd676</td>\n",
       "      <td>\"\\n\\nNOTE\\n and  continue to vandalize this pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136092</th>\n",
       "      <td>d7dfd06388dafe24</td>\n",
       "      <td>hey buddy \\n\\nFUCK YOU</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146372</th>\n",
       "      <td>2b2abfa22ba63b2f</td>\n",
       "      <td>\":::Even during the 1891 census, castes like V...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106996</th>\n",
       "      <td>3c1aad0bb324236f</td>\n",
       "      <td>And...\\nTELL THE WIKITRUTH.75.21.101.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "154640  b0f437119b56c6f4  \"\\nSo I'm still waiting for an actual reason. ...   \n",
       "153091  972f3e1770dcd676  \"\\n\\nNOTE\\n and  continue to vandalize this pa...   \n",
       "136092  d7dfd06388dafe24                             hey buddy \\n\\nFUCK YOU   \n",
       "146372  2b2abfa22ba63b2f  \":::Even during the 1891 census, castes like V...   \n",
       "106996  3c1aad0bb324236f            And...\\nTELL THE WIKITRUTH.75.21.101.63   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "154640      0             0        0       0       0              0  \n",
       "153091      0             0        0       0       0              0  \n",
       "136092      1             1        1       0       1              0  \n",
       "146372      0             0        0       0       0              0  \n",
       "106996      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_train = train[\"comment_text\"].fillna(\"CVxTz\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"CVxTz\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\"\\nSo I\\'m still waiting for an actual reason.  Provide a source that disputes him as the GOAT.  Better yet, provide several so that you can say that he is NOT \"\"widely considered the GOAT\"\".  As opposed to the fact that he IS \"\"widely considered the GOAT\"\" because there are myriads of sources that support the latter statement. \"',\n",
       "       '\"\\n\\nNOTE\\n and  continue to vandalize this page by including non-sourced information pertaining to a boyfriend named \"\"Chad Eagleton.\"\"  TXmaster uploaded a picture on 2/17 in which he states that he is Chad Eagleton.  These claims are most likely dubious attempts by the two users (who are probably actually the same person) to claim that they are dating Carrie Underwood.  As none of their claims are sourced, I along with several other users continue to delete them.  Neither user has stepped up to the challenge of providing a source for their claims.  Please continue to delete their constant vandalism.  \"',\n",
       "       'hey buddy \\n\\nFUCK YOU', ...,\n",
       "       '\"...And of course the Pashto and Urdu pronunciation of the second word - \"\"Pakhtunkhwa\"\" is also missing in the article.  \"',\n",
       "       \"Ratio vis a vis edit summaries \\n\\nI've been unable to find any cases where the edit summary principles have really been used as ratio dicendi rather than just obiter dicta, except that I suppose to stretch a point one might say that the judgement in Gzornenplatz, Kevin Baas, Shorne, VeryVerily uses it as a ratio for the FoF that they failed to discuss reverts.\",\n",
       "       '\"\\n\\nBell inequalities\\n\\nI\\'ve changed back the link in Bell state to Bell\\'s theorem.  Having a link to Bell\\'s inequalities is absurd since that page doesn\\'t even acknowledge entanglement. This action will likely be followed by more personal attacks on me from CT (I assume you followed the discussion throughout the  various talk pages, including my own).  This is a long term problem;   CT seems to have found a haven in WP where they feel they can claim and freely assert their \"\"authority\"\" on the subject of local realism and experimental tests of Bell\\'s inequalities. I fear the WP structure is much too weak to do anything about it. The typical wikipedian response seems to be \"\"Go to mediation\"\" etc., etc. But the problem only shifts to someplace else.  14:17, 17 Feb 2005 (UTC)\"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sentences_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,\",\n",
       "       '== From RfC == \\n\\n The title is fine as it is, IMO.',\n",
       "       '\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland â€”  /  \"', ...,\n",
       "       '\" \\n\\n == Okinotorishima categories == \\n\\n I see your changes and agree this is \"\"more correct.\"\"  I had gotten confused, but then found this: \\n :... while acknowledging Japan\\'s territorial rights to Okinotorishima itself ... \\n However, is there a category for  \\n :... did not acknowledge Japan\\'s claim to an exclusive economic zone (EEZ) stemming from Okinotorishima. \\n That is, is there a category for \"\"disputed EEZ\"\"s?   \"',\n",
       "       '\" \\n\\n == \"\"One of the founding nations of the EU - Germany - has a Law of Return quite similar to Israel\\'s\"\" == \\n\\n This isn\\'t actually true, is it? Germany allows people whose ancestors were citizens of Germany to return, but AFAIK it does not allow the descendants of Anglo-Saxons to \"\"return\"\" to Angeln and Saxony. Israel, by contrast, allows all Jews to \"\"return\"\" to Israel, even if they can\\'t trace a particular ancestral line to anyone who lived in the modern state or even mandate Palestine. â€” \"',\n",
       "       '\" \\n :::Stop already. Your bullshit is not welcome here. I\\'m no fool, and if you think that kind of explination is enough, well pity you.    \"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sentences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    1, 1873,  446],\n",
       "       [   0,    0,    0, ...,   92, 2728,  199],\n",
       "       [   0,    0,    0, ..., 3583,  129,    6],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   10,    1,   23],\n",
       "       [   0,    0,    0, ...,    2,  519, 1416],\n",
       "       [1556,   32,   57, ..., 2280,  469,  182]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  145,  493,   84],\n",
       "       [   0,    0,    0, ...,   11,    8, 2828],\n",
       "       [   0,    0,    0, ...,  109,   15,  355],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   12, 1652,  358],\n",
       "       [   0,    0,    0, ..., 9857, 3507,  355],\n",
       "       [   0,    0,    0, ...,  100, 5216,    6]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    embed_size = 128\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = Bidirectional(LSTM(50, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "                 )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "batch_size = 32\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"weights_base.best.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose = 1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.ModelCheckpoint at 0x7f1dc525f908>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.EarlyStopping at 0x7f1dc52470f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 1640s 11ms/step - loss: 0.0643 - acc: 0.9788 - val_loss: 0.0502 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05020, saving model to weights_base.best.hdf5\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 1631s 11ms/step - loss: 0.0459 - acc: 0.9831 - val_loss: 0.0467 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05020 to 0.04668, saving model to weights_base.best.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1dc51caf28>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [checkpoint, early]\n",
    "model.fit(X_t, y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[list_classes] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"../submission/submission_03.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
